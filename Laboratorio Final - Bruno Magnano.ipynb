{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2: Armado de un esquema de aprendizaje automático\n",
    "\n",
    "En el laboratorio final se espera que puedan poner en práctica los conocimientos adquiridos en el curso, trabajando con un conjunto de datos de clasificación.\n",
    "\n",
    "El objetivo es que se introduzcan en el desarrollo de un esquema para hacer tareas de aprendizaje automático: selección de un modelo, ajuste de hiperparámetros y evaluación.\n",
    "\n",
    "El conjunto de datos a utilizar está en `./data/loan_data.csv`. Si abren el archivo verán que al principio (las líneas que empiezan con `#`) describen el conjunto de datos y sus atributos (incluyendo el atributo de etiqueta o clase).\n",
    "\n",
    "Se espera que hagan uso de las herramientas vistas en el curso. Se espera que hagan uso especialmente de las herramientas brindadas por `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "from ml.visualization import plot_confusion_matrix, plot_learning_curve\n",
    "\n",
    "\n",
    "# TODO: Agregar las librerías que hagan falta\n",
    "\n",
    "np.random.seed(0)  # Para mayor determinismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nvo_release\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from ml.visualization import plot_confusion_matrix, classifier_boundary\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Perceptron, Ridge\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "np.random.seed(0)  #Para mayor determinismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "La celda siguiente se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>LOAN</th>\n",
       "      <th>MORTDUE</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>YOJ</th>\n",
       "      <th>DEROG</th>\n",
       "      <th>DELINQ</th>\n",
       "      <th>CLAGE</th>\n",
       "      <th>NINQ</th>\n",
       "      <th>CLNO</th>\n",
       "      <th>DEBTINC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4700</td>\n",
       "      <td>88026.0</td>\n",
       "      <td>115506.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.248332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.209023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>19300</td>\n",
       "      <td>39926.0</td>\n",
       "      <td>101208.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.051638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.545694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5700</td>\n",
       "      <td>71556.0</td>\n",
       "      <td>79538.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.643085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>41.210012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13000</td>\n",
       "      <td>44875.0</td>\n",
       "      <td>57713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.990324</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.602076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>19300</td>\n",
       "      <td>72752.0</td>\n",
       "      <td>106084.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.707100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.686106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET   LOAN  MORTDUE     VALUE   YOJ  DEROG  DELINQ       CLAGE  NINQ  \\\n",
       "0       0   4700  88026.0  115506.0   6.0    0.0     0.0  182.248332   0.0   \n",
       "1       0  19300  39926.0  101208.0   4.0    0.0     0.0  140.051638   0.0   \n",
       "2       0   5700  71556.0   79538.0   2.0    0.0     0.0   92.643085   0.0   \n",
       "3       0  13000  44875.0   57713.0   0.0    1.0     0.0  184.990324   1.0   \n",
       "4       0  19300  72752.0  106084.0  11.0    0.0     0.0  193.707100   1.0   \n",
       "\n",
       "   CLNO    DEBTINC  \n",
       "0  27.0  29.209023  \n",
       "1  14.0  31.545694  \n",
       "2  15.0  41.210012  \n",
       "3  12.0  28.602076  \n",
       "4  13.0  30.686106  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "display(dataset.head())\n",
    "\n",
    "# División entre instancias y etiquetas\n",
    "X, y = dataset.iloc[:, 1:], dataset.TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nvo_release\n",
    "\n",
    "dataset = pd.read_csv(\"./data/loan_data.csv\", comment=\"#\")\n",
    "print('\\nLongitud del dataset: '+str(len(dataset))+'\\n')\n",
    "\n",
    "#División entre instancias y etiquetas\n",
    "X, y = dataset.drop(columns=['TARGET']), dataset.TARGET\n",
    "\n",
    "print('Dataset:')\n",
    "display(X.head(10))\n",
    "\n",
    "print('Target:')\n",
    "display(y.head(10))\n",
    "\n",
    "print('Frecuencias del Target')\n",
    "display(dataset.TARGET.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: División de datos en conjuntos de entrenamiento y evaluación\n",
    "\n",
    "La primer tarea consiste en dividir el conjunto de datos cargados en el apartado anterior en conjuntos de entrenamiento (o *training*) y evaluación (o *test*).\n",
    "\n",
    "El primero será utilizado para la creación/selección del modelo de clasificación. El segundo se utilizará sólo al final (una vez elegidos los mejores hiperparámetros) para ver cuál es el resultado final del modelo sobre un conjunto de datos independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\users\\F78051B\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Dividir en datos de entrenamiento y evaluación\n",
    "\n",
    "# Splitting the dataset into the Training set and the Test set\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.30, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nvo_release\n",
    "\n",
    "# Utilizamos aproximadamente 80% de los datos para entrenamiento y 20% para validación# Utiliz \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Necesario para poder hacer un regresor por feature\n",
    "feature_map = {feature: idx for idx, feature in enumerate(['LOAN', 'MORTDUE','VALUE','YOJ','DEROG','DELINQ', \n",
    "                                                           'CLAGE','NINQ','CLNO', 'DEBTINC'])}\n",
    "print(\"Listado de atributos\\n====================\")\n",
    "for feature in feature_map:\n",
    "    print(\"- %s\" % feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Elección de un modelo\n",
    "\n",
    "Basándose en lo visto en el teórico escojan y justifiquen un modelo de aprendizaje automático. Recuerden que los pasos para elegir un modelo son:\n",
    "\n",
    "### Selección de hipótesis\n",
    "\n",
    "*TODO*\n",
    "\n",
    "### Selección de regularizador\n",
    "\n",
    "*TODO*\n",
    "\n",
    "### Selección de función de coste\n",
    "\n",
    "*TODO*\n",
    "\n",
    "### Justificación de las selecciones\n",
    "\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NVO_RELEASE\n",
    "\n",
    "Ejercicio 2: Elección de un modelo\n",
    "Basándose en lo visto en el teórico escojan y justifiquen un modelo de aprendizaje automático. Recuerden que los pasos para elegir un modelo son:\n",
    "\n",
    "Selección de hipótesis\n",
    "Elegimos a la regresión logística, con función:\n",
    "\n",
    "$$h_w(x)= \\frac{1}{1+\\exp(-w^T x))}$$\n",
    "Selección de regularizador\n",
    "Se va a calcular cual de los dos regularizadores (L1 y L2) presenta mejores resultados y se procederá a elegirlo por rendimiento.\n",
    "\n",
    "Selección de función de coste\n",
    "$$L(w)=- \\sum_{i=1}^N y_i \\log (h_w(x_i)) + (1-y_i) \\log (1-h_w(x_i))$$\n",
    "Justificación de las selecciones\n",
    "Como se mencionó anteriormente, el problema cae dentro de un problema de clasificación binaria, para la cual se escoge a la regresión logística como hipótesis, ya que la salida toma valores de 0 y/o 1. Además, la regresión será de atributos regulares, se escogió esta característica para simplificar el modelo, ya que se utilizarán todos los features del dataset. Esto se decidió luego de probar diversas combinaciones de datos y descubrir que los conjuntos no eran para nada linealmente separables, lo que nos llevo a encontrar que usando todas las features mejorábamos la exactitud. En cuanto al regularizador, se escogerá L2 simplemente debido a que es más usada y brinda mejores resultados en general que L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb6c1c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "plt.scatter(X_train[\"MORTDUE\"], y_train, s=40, c=y_train, cmap=plt.cm.Spectral)\n",
    "\n",
    "# clf = linear_model.LogisticRegressionCV()\n",
    "# clf.fit(X_train,y_train)\n",
    "\n",
    "# # plot_decision_boundary(lambda x: clf.predict(x))\n",
    "# plt.title(\"Regresión logística\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Selección de hiperparámetros\n",
    "\n",
    "Utilizando búsqueda exhaustiva (*grid search*) con *5-fold cross-validation* y utilizando como métrica el área bajo la curva de ROC (o *ROC-AUC*), hagan una selección de los mejores hiperparámetros para su conjunto de datos y el modelo que hayan elegido en el apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de hiperparámetros para función de coste \"hinge\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.823 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.822 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.820 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.693 (+/-0.066) para los parámetros {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.821 (+/-0.000) para los parámetros {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.692 (+/-0.054) para los parámetros {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.724 (+/-0.032) para los parámetros {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.695 (+/-0.063) para los parámetros {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.587 (+/-0.082) para los parámetros {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92       477\n",
      "          1       0.00      0.00      0.00        80\n",
      "\n",
      "avg / total       0.73      0.86      0.79       557\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\users\\F78051B\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Exploración de hiperparámetros para función de coste \"log\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.618 (+/-0.056) para los parámetros {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.694 (+/-0.067) para los parámetros {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.823 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.693 (+/-0.066) para los parámetros {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.607 (+/-0.075) para los parámetros {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.695 (+/-0.066) para los parámetros {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.823 (+/-0.000) para los parámetros {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.694 (+/-0.067) para los parámetros {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.564 (+/-0.100) para los parámetros {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.03      0.06       477\n",
      "          1       0.14      0.93      0.24        80\n",
      "\n",
      "avg / total       0.62      0.16      0.08       557\n",
      "\n",
      "\n",
      "================================================\n",
      "\n",
      "# Exploración de hiperparámetros para función de coste \"perceptron\"\n",
      "\n",
      "Mejor conjunto de parámetros:\n",
      "{'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Puntajes de la grilla:\n",
      "\n",
      "Exactitud: 0.805 (+/-0.001) para los parámetros {'alpha': 0.1, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.814 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.822 (+/-0.000) para los parámetros {'alpha': 0.1, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.820 (+/-0.000) para los parámetros {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.551 (+/-0.081) para los parámetros {'alpha': 0.01, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.414 (+/-0.086) para los parámetros {'alpha': 0.01, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.740 (+/-0.028) para los parámetros {'alpha': 0.001, 'eta0': 0.1, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.695 (+/-0.059) para los parámetros {'alpha': 0.001, 'eta0': 0.01, 'learning_rate': 'constant'}\n",
      "Exactitud: 0.821 (+/-0.000) para los parámetros {'alpha': 0.001, 'eta0': 0.001, 'learning_rate': 'constant'}\n",
      "\n",
      "Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.42      0.56       477\n",
      "          1       0.15      0.60      0.24        80\n",
      "\n",
      "avg / total       0.76      0.44      0.52       557\n",
      "\n",
      "\n",
      "================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbd4c0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "for idx, loss in enumerate(('hinge', 'log', 'perceptron'), start=1):\n",
    "    exploring_params = {\n",
    "        'learning_rate': ['constant'],\n",
    "        'eta0': [0.1, 0.01, 0.001],  # Tasa de entrenamiento\n",
    "        'alpha': [0.1, 0.01, 0.001]  # Tasa de regularización\n",
    "    }\n",
    "    m = SGDClassifier(loss=loss, tol=1e-3)\n",
    "    model = GridSearchCV(m, exploring_params, cv=5, scoring='accuracy')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"# Exploración de hiperparámetros para función de coste \\\"%s\\\"\" % loss, end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"Mejor conjunto de parámetros:\")\n",
    "    print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "    print(\"Puntajes de la grilla:\", end=\"\\n\\n\")\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "    print()\n",
    "\n",
    "    \n",
    "    print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\\n\")\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"================================================\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nvo_release\n",
    "\n",
    "plt.figure(figsize=(20, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "  \n",
    "for idx, penalty in enumerate(('l1', 'l2'), start=1):\n",
    "    exploring_params = {\n",
    "        'C': [1./40., 1./30., 1./20., 1./10., 1./1., 1./0.9, 1./0.8, 1./0.5, 1./0.1, 1./0.01],  # Tasa de regularización\n",
    "        'tol': [1e-3, 1e-5], \n",
    "        'max_iter': [10000, 15000, 20000]\n",
    "    }  \n",
    "    \n",
    "    m = LogisticRegression(penalty=penalty)\n",
    "    model = GridSearchCV(m, exploring_params, cv=5, scoring='roc_auc')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"####################################################################\")\n",
    "    print(\"    Exploración de hiperparámetros para función de coste \\\"%s\\\"    \" % penalty, end=\"\\n\")\n",
    "    print(\"####################################################################\\n\")\n",
    "    \n",
    "    print(\"Mejor conjunto de parámetros:\")\n",
    "    print(model.best_params_, end=\"\\n\\n\")\n",
    "\n",
    "    print(\"Puntajes de la grilla:\", end=\"\\n\")\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"Exactitud: %0.3f (+/-%0.03f) para los parámetros %r\" % (mean, std ** 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\")\n",
    "    y_true, y_pred = y_test, model.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "    \n",
    "    print(\"==================================================================================\", end=\"\\n\\n\")\n",
    "\n",
    "    plt.subplot(1, 2, idx)\n",
    "    plot_confusion_matrix(confusion_matrix(y_true, y_pred),\n",
    "                          classes=[0,1], title=\"Matriz de confusión para %s\" % penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbc82e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    plt.subplot(1, 3, idx)\n",
    "    plot_confusion_matrix(confusion_matrix(y_true, y_pred),\n",
    "                          classes=dataset.TARGET, title=\"Matriz de confusión para %s\" % loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Métricas sobre el conjunto de evaluación\n",
    "\n",
    "Una vez encontrados los mejores hiperparámetros para el modelo seleccionado en los apartados anteriores se evalúa el modelo final entrenado sobre el conjunto de datos de evaluación seleccionado en el ejercicio 1. Pueden utilizar las métricas que crean convenientes. Es mejor utilizar más de una métrica. Particularmente el *reporte de clasificación* y la *matriz de confusión* son buenos ejemplos de métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros determinados en el punto anterior:\n",
    "penalty = 'l2' \n",
    "C = 1./0.9      \n",
    "max_iter = 20000 \n",
    "tol = 0.001      \n",
    "\n",
    "model = LogisticRegression(penalty=penalty, C=C, max_iter=max_iter, tol=tol, solver='newton-cg')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el desempeño del clasificador utilizando la exactitud (accuracy) sobre el conjunto\n",
    "# de datos de entrenamiento (X_train, y_train) y lo comparamos con el de validación (X_test, y_test)\n",
    "# La exactitud toma valor en el rango [0, 1] donde más alto es mejor\n",
    "print('Exactitud para entrenamiento: %.2f' %  accuracy_score(y_train, model.predict(X_train)))\n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "\n",
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train)),\n",
    "                classes=[0,1],title='Matriz de confusión para entrenamiento (sin normalizar)')\n",
    "plt.subplot(2, 2, 3)\n",
    "plot_confusion_matrix(confusion_matrix(y_train, model.predict(X_train)),\n",
    "                classes=[0,1],normalize=True,title='Matriz de confusión para entrenamiento (normalizando)')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_test, model.predict(X_test)),\n",
    "                classes=[0,1],title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(2, 2, 4)\n",
    "plot_confusion_matrix(confusion_matrix(y_test, model.predict(X_test)),\n",
    "                classes=[0,1], normalize=True,title='Matriz de confusión para validación (normalizando)')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte de clasificación\n",
    "\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de entrenamiento):\", end=\"\\n\")\n",
    "y_true, y_pred = y_train, model.predict(X_train)\n",
    "print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "    \n",
    "print(\"==================================================================================\", end=\"\\n\\n\")\n",
    "\n",
    "print(\"Reporte de clasificación para el mejor clasificador (sobre conjunto de evaluación):\", end=\"\\n\")\n",
    "y_true, y_pred = y_test, model.predict(X_test)\n",
    "print(classification_report(y_true, y_pred), end=\"\\n\\n\")\n",
    "    \n",
    "print(\"==================================================================================\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 (opcional): Curvas de ROC\n",
    "\n",
    "Como ejercicio adicional (opcional), pueden redefinir el umbral de decisión óptimo del problema a partir de los resultados que muestren curvas de ROC como justificación. \n",
    "\n",
    "Pueden ver esto mediante la [graficación de las curvas de ROC](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html). En el link que se les brinda se muestra como hacer para graficar curvas de ROC para problemas multiclase. Sin embargo se puede adaptar fácilmente a un problema binario obviando la parte donde se calcula la curva clase por clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Redefinir umbral de clasificación a través de los resultados vistos por graficar curvas de ROC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_true, y_pred = y_test, model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_pred, pos_label=1)\n",
    "\n",
    "print(\"True Positive Rates:\")\n",
    "print(tpr)\n",
    "print(\"False Positive Rates:\")\n",
    "print(fpr)\n",
    "print(\"Umbrales utilizados en el análisis:\")\n",
    "print(threshold)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El umbral correspondiente al modelo que utilizamos inicialmente corresponde a un TPR de 0.93 y a un FPR de 0.70 aproximadamente. Esto corresponde a un umbral utilizado muy bajo. Que provoca que nos ubiquemos mas \"al final de la curva\". Si observamos la matriz de confusión nos encontramos frente a una cantidad considerable de falsos positivos, con lo cual sería deseable disminuir nuestro FPR. Para eso si observamos el gráfico deberíamos acercarnos hacia \"el centro de la curva\". Nos quedaremos con un FPR de aproximadamente 0.12 y un TPR de aproximadamente 0.65 que corresponde a un umbral de 0.20. Con esto lograremos mejorar nuestros Falsos Positivos, por supuesto a un costo, no muy grande, de true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bin = []\n",
    "for prediction in y_pred:\n",
    "    if prediction > 0.20:\n",
    "        y_pred_bin.append(1)\n",
    "    else:\n",
    "        y_pred_bin.append(0)\n",
    "        \n",
    "print('Exactitud para validación: %.2f' % accuracy_score(y_true, y_pred_bin))\n",
    "\n",
    "plt.figure(figsize=(14, 10), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_confusion_matrix(confusion_matrix(y_true, y_pred_bin),\n",
    "                classes=[0,1],title='Matriz de confusión para validación (sin normalizar)')\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_confusion_matrix(confusion_matrix(y_true, y_pred_bin),\n",
    "                classes=[0,1], normalize=True,title='Matriz de confusión para validación (normalizando)')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo se puede observar hemos disminuido a la mitad los falsos positivos sin afectar practicamente a la precisión."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
